<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>CEMA 0907: Statistics in the Real World</title>
    <meta charset="utf-8" />
    <meta name="author" content="Anthony Scotina" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# CEMA 0907: Statistics in the Real World
## Confidence Intervals
### Anthony Scotina

---






class: center, middle, frame

# Introduction

---

# Recap

If *sampling* of a sample of size `\(n\)` is done at **random**, then the resulting sample is *unbiased* and **representative** of the **population**. 
- Thus, the **sample statistic** from the representative sample represents a "good guess" of the (unknown) **population parameter**. 

Using the `bowl` data frame in the `moderndive` R package, we used the **sample proportion**, `\(\hat{p}\)`, to estimate the **population proportion**, `\(p\)`. 

Generally, we will use the *sample* to **infer** about the *population*. 

---

# In reality...

In *most cases*, we don't have the population values like we did with the `bowl` data frame, and we don't take many samples from the population. 

- We only have a single sample of data from a larger population!

While the **sample statistic** represents our single *best guess* at the (unknown) **population parameter**, we would also like to create a *range of plausible values* for the population parameter. 

- This range is called a **confidence interval**. 

--

How do we use a single sample to get some idea of how other samples might vary in terms of their statistic values?

- **Bootstrapping**

---

# Needed Packages 


```r
library(moderndive)
library(nycflights13)
library(tidyverse)
library(infer)
```

---

class: center, middle, frame

# Bootstrapping

---

# `pennies_sample`


```r
pennies_sample
```

```
# A tibble: 50 × 2
      ID  year
   &lt;int&gt; &lt;dbl&gt;
 1     1  2002
 2     2  1986
 3     3  2017
 4     4  1988
 5     5  2008
 6     6  1983
 7     7  2008
 8     8  1996
 9     9  2004
10    10  2000
# … with 40 more rows
```

**Question**: What is the *average year* on US pennies in 2019?

- Can we use the sample of 50 pennies to help answer this question?

---

# Exploratory Data Analysis: Data Visualization

.pull-left[
![](08-Confidence_Intervals_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

.pull-right[
Most of the ages are between 1980 and 2000, though there is a large spike in 2018. 

- If this sample is **representative** of the population of US pennies, we would expect the distribution of *all* pennies' year to have a similar shape. 
]

---

# Exploratory Data Analysis: Summary Statistics

Because we are interested in the **mean** year of *all* US pennies in 2019, let's calculate the **sample mean**, `\(\bar{x}\)`, of our 50 pennies using `mean()`:

```r
x_bar = mean(pennies_sample$year)
x_bar
```

```
[1] 1995.44
```

Therefore, our **point estimate** is `\(\bar{x}=1995.44\)`. This represents our *best guess* at the **population mean** age of all US pennies, `\(\mu\)`. 

---

# Sampling Variability

**Why are we interested in this?**

*Every* **sample statistic** has some variability. 
- Suppose you take a random sample of 50 Brown University students and five are left-handed. 

--

If you take a *different* random sample of 50 Brown University students, how many would you *expect* to be left-handed?
- Suppose three are left-handed. Is that surprising?
- Would 40 left-handed students out of 50 be surprising?

**Two ways to measure variability**:

1. Theory (Central Limit Theorem, etc.) -- AP/Introductory Statistics
2. **Simulation** (e.g., *bootstrapping*) -- **THIS CLASS**

---

# The Bootstrapping Process

Bootstrapping uses a process of sampling **with replacement** from our original sample to create new bootstrap samples of the **same size** as our original sample.

We can generate a *single bootstrap sample* by using the `rep_sample_n()` function from earlier:



```r
bootstrap_sample1 = 
  rep_sample_n(pennies_sample, size = 50, reps = 1, replace = TRUE)
```

--

- Notice that `size=50`. This *isn't an arbitrary number*. When bootstrapping, the `size` value will *always be the same as the original sample size*!

- We add a new argument to `rep_sample_n()`, `replace = TRUE`. This means that when a penny is selected for our **bootstrap sample**, it has the chance to be selected *again*. 

---

# Why bootstrap?

Ideally, you are able to take thousands of samples from the same population and obtain an estimate (close to) an *exact* population parameter, and know exactly how much each sample **varies**. 
- **Example**: Taking many samples of red and white balls from a bowl of 2,400 balls

--

But this is **impossible**!
- So we *improvise* and copy our sample many times to **simulate** a population. 

---

class: center, middle, frame

# The `infer` Package for Statistical Inference

---

# `infer`

The `infer` package provides a useful resource in building **confidence intervals** and conducting **hypothesis tests** (more on those later). 

There are several *verb-named functions* that build in order. 

.center[
&lt;img src="infer_hex.png" width="30%" /&gt;
]

---

# Step 1: `specify()`

The `specify()` function is used primarily to choose which variables will be the focus of the statistical inference.
- This is done using the `response = ` argument:


```r
pennies_sample %&gt;%
  specify(response = year)
```

```
Response: year (numeric)
# A tibble: 50 × 1
    year
   &lt;dbl&gt;
 1  2002
 2  1986
 3  2017
 4  1988
 5  2008
 6  1983
 7  2008
 8  1996
 9  2004
10  2000
# … with 40 more rows
```

---

# Step 2: `generate()` replicates

After `specify()`-ing the main variable of interest, we use `generate()` to generate **bootstrap samples** (i.e., *replicates*) from the original sample. 
- Here, we can easily create 1,000 bootstrap samples:

```r
thousand_bootstrap_samples = pennies_sample %&gt;%
  specify(response = year) %&gt;%
  generate(reps = 1000, type = "bootstrap")
```

If you use `View(thousand_bootstrap_samples)`, you will see that there are 50,000 rows! 
- We took 1,000 bootstrap samples, each of size 50. 

---

# Step 3: `calculate()` summary statistics

Once we have 1,000 **bootstrap samples**, we need to calculate a **summary statistic** for each sample. 
- In this example, the *summary statistic* is the **mean**. 

```r
bootstrap_distribution = pennies_sample %&gt;% 
  specify(response = year) %&gt;% 
  generate(reps = 1000, type = "bootstrap") %&gt;% 
  calculate(stat = "mean")
```

--

This generates a data frame with 1,000 rows: each row containing the sample mean of the respective **bootstrap sample**. 
- This set of 1,000 sample means represents a **bootstrap distribution**. 

---

# Step 4: `visualize()` the results

.center[
&lt;img src="infer.png" width="515" /&gt;
]

---

# Step 4: `visualize()` the results


```r
visualize(bootstrap_distribution)
```

&lt;img src="08-Confidence_Intervals_files/figure-html/unnamed-chunk-13-1.png" width="50%" /&gt;

---

class: center, middle, frame

# Confidence Intervals

---

# Confidence Intervals

A **confidence interval** gives a range of *plausible values* for a population parameter. 
- Using *only* a **sample statistic** to estimate a parameter is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net.

.center[
&lt;img src="fishing.png" width="50%" /&gt;
]

---

# Confidence Intervals

Confidence intervals depend on a specified **confidence level**, with...
- *higher* confidence levels corresponding to *wider* confidence intervals, and
- *lower* confidence levels corresponding to *narrower* confidence intervals. 

Common **confidence levels** include 90%, 95%, and 99%.

--

Using the **bootstrap distribution** (i.e., `bootstrap_distribution` from earlier), there are two ways we can obtain a confidence interval for the population mean age of US pennies:

1. The **percentile method**

2. The **standard error method**

---

# The Percentile Method

The only thing you need to do here is to use the `get_ci()` function from the `infer` package:


```r
percentile_ci = bootstrap_distribution %&gt;% 
  get_ci(level = 0.95, type = "percentile") 
# 0.95 and "percentile" are default values
percentile_ci
```

```
# A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1    1991.    2000.
```

--

The **percentile method** gives us the 2.5th and the 97.5th *percentiles* of the bootstrap distribution. 

- Our range of plausible values for the mean year of US pennies in 2019 is between 1991 and 2000 years, with **95% confidence**. 

---

# Visualizing the CI

A cool thing you can do in R is to use the `visualize()` function to plot the *confidence interval* on top of the bootstrap distribution histogram. 
- Run the following:


```r
visualize(bootstrap_distribution) + 
  shade_ci(endpoints = percentile_ci, 
           color = "hotpink", fill = "chartreuse")
```

---

# The Standard Error Method

Our **bootstrap distribution** is close to symmetric and bell-shaped, or **Normally distributed**. 

If this is the case, we can use a shortcut formula to calculate the lower and upper endpoints of the confidence interval: 
`$$\bar{x}\pm (multiplier)\cdot SE$$`
where `\(\bar{x}\)` is the **sample statistic** (`x_bar`, obtained earlier), and `\(SE\)` stands for **standard error**, or the *standard deviation of the bootstrap distribution*.
- For a 95% confidence interval, the value of *multiplier* is **1.96**. 

---

# Why 1.96?

For any distribution that is **Normally-shaped**, roughly 95% of the values lie within *two standard deviations of the mean*.

- In the case of a bootstrap distribution, these standard deviations are also **standard errors**. 

Thus for a 95% confidence interval for the **mean**, 95% of values of the bootstrap distribution will lie within `\(\pm\)` 1.96 (or nearly 2) *standard errors* of `\(\bar{x}\)`. 

--

In a **Normal distribution**, roughly *68%* of the values lie within *one standard deviation of the mean*. 

- What would the *multiplier* be for a 68% confidence interval?


---

# The Standard Error Method

As with the **percentile method**, we use the `get_ci()` function here. But there are a few slight differences:

```r
standard_error_ci = bootstrap_distribution %&gt;% 
* get_ci(level = 0.95, type = "se", point_estimate = x_bar)
standard_error_ci
```

```
# A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1    1991.    2000.
```

- We have to specify that we want a CI using the **standard error method** (using `type = "se"`). 

- We also have to provide the **point estimate**, which you should calculate beforehand. 

---

# The Standard Error Method

As with the **percentile method**, we use the `get_ci()` function here. But there are a few slight differences:

```r
standard_error_ci = bootstrap_distribution %&gt;% 
  get_ci(level = 0.95, type = "se", point_estimate = x_bar)
standard_error_ci
```

```
# A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1    1991.    2000.
```

- Our range of plausible values for the mean year of US pennies in 2019 is between 1991 and 2000 years, with **95% confidence**. 
    - This is *identical* to the CI obtained using the **percentile method** (b/c the bootstrap distribution is **Normal**)!
    
---

class: center, middle, frame

# Interpreting the Confidence Interval

---

# Interpreting the Confidence Interval

We have done a lot of calculations in this module, but *what does it all mean*?

The purpose of confidence intervals is to provide a range of plausible values for an *unknown* parameter (in this case, the population mean `\(\mu\)`). 
- Using the **percentile method**, one such interval is `\([1991, 2000]\)`. 

--

Let's modify `pennies_sample` to **simulate** a population of US pennies.

```r
pennies_pop = pennies_sample %&gt;%
  sample_n(10000, replace = TRUE)

mean(pennies_pop$year)
```

```
[1] 1995.146
```

--

Thus, `\(\mu=1995\)` (approx.) which *falls in the confidence interval*. 

---

# Using a new `pennies_sample`

We can use the `infer` pipeline to re-do the entire set of exercises today, but using a *new* sample of pennies from the `pennies` data frame:



```r
bootstrap_distribution_new = pennies_pop %&gt;%
  rep_sample_n(size = 40, reps = 1) %&gt;%
  specify(response = year) %&gt;% 
  generate(reps = 1000) %&gt;% 
  calculate(stat = "mean")
bootstrap_distribution_new %&gt;%
  get_ci()
```

```
## # A tibble: 1 × 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1    1992.    2001.
```

This new confidence interval *also* contains `\(\mu\)` (1995). 

---

# Calculating Many CIs

We can repeat this process 100 times (don't worry about the code), and generate 100 95% confidence intervals:

.center[
&lt;img src="ci_sim.png" width="60%" /&gt;
]

---

# Calculating Many CIs

Using 95% as our **confidence level**, *approximately* 94 of the CIs contained the population mean `\(\mu=1995.133\)`, while 6 did not. 

**What does this mean?**

- The procedure we have used to generate confidence intervals is "*95% reliable*" in that we can expect it to include the true population parameter **approximately** 95% of the time *if the process is repeated*.

---

# Back to our example...

**What is a precise interpretation of a confidence interval?**

Recall our *original 95% confidence interval* using the **percentile method**: `\([1991, 2000]\)`. 

**Interpretation**: We are **95% confident** that the average year on US pennies in 2019 is between 1991 and 2000, using the **percentile method**. 

---

# Interpretating a CI

In general...

**Precise interpretation**: If we repeated our sampling procedure a large number of times, we expect about 95% of the resulting confidence intervals to capture the value of the population parameter.

**Short-hand interpretation**: We are 95% “confident” that a 95% confidence interval captures the value of the population parameter.

---

# Width of Confidence Interval

**Confidence level**

In order to be more confident in our best guess of a range of values, we need to widen the range of values.
- The higher the *confidence level*, the wider a confidence interval will be. 

--


```r
bootstrap_distribution %&gt;% 
  get_ci(level = 0.80, type = "percentile") 
```

```
## # A tibble: 1 × 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1    1993.    1998.
```

---

# Width of Confidence Interval

**Confidence level**

In order to be more confident in our best guess of a range of values, we need to widen the range of values.
- The higher the *confidence level*, the wider a confidence interval will be. 


```r
bootstrap_distribution %&gt;% 
  get_ci(level = 0.95, type = "percentile") 
```

```
## # A tibble: 1 × 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1    1991.    2000.
```

---

# Width of Confidence Interval

**Confidence level**

In order to be more confident in our best guess of a range of values, we need to widen the range of values.
- The higher the *confidence level*, the wider a confidence interval will be. 


```r
bootstrap_distribution %&gt;% 
  get_ci(level = 0.99, type = "percentile") 
```

```
## # A tibble: 1 × 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1    1990.    2001.
```

---

# Impact of Sample Size

In general, *larger sample sizes tend to produce narrower confidence intervals*. 
- As our sample size increases, our estimate gets more *precise*. 
    - Also, the **standard error decreases**. 
    
For example, a 95% confidence interval with `\(n=50\)` will be *narrower* than a 95% confidence interval with `\(n=25\)`. 

---

class: center, middle

# Bootstrap vs. Sampling Distributions

---

# Comparing Bootstrap and Sampling Distributions

Recall that in the last module, we constructed a **sampling distribution** of the proportion of red balls in a bowl, using the `bowl` dataset. 

- This was done by taking 1,000 *replications* of size 100 (or 10, or 50) *without replacement* from the "population" of 2,400 objects in the bowl. 

The reason the **bootstrap** is so useful in application is that we will never actually take 1,000 unique samples from a population. 

- The **bootstrap distribution** serves as an *approximation* to the sampling distribution that we constructed before. 

--

Let's compare the two distributions and see how well they match!

---

# Sampling Distribution (from Module 3)




```r
virtual_sample_50 = rep_sample_n(bowl, size = 50, reps = 1000)
prop_red_50 = tally(color ~ replicate, format = "proportion", 
                    data = virtual_sample_50)["red", ]
gf_histogram( ~ prop_red_50)
```

&lt;img src="08-Confidence_Intervals_files/figure-html/unnamed-chunk-27-1.png" width="50%" /&gt;

---

# Bootstrap Distribution




```r
set.seed(12)
bowl_sample_1 = rep_sample_n(bowl, size = 50, reps = 1)
bootstrap_distribution = bowl_sample_1 %&gt;% 
  specify(response = color, success = "red") %&gt;% 
  generate(reps = 1000, type = "bootstrap") %&gt;% 
  calculate(stat = "prop")
gf_histogram( ~ stat, data = bootstrap_distribution)
```

&lt;img src="08-Confidence_Intervals_files/figure-html/unnamed-chunk-29-1.png" width="40%" /&gt;
            
---

# Comparison

.pull-left[
![](08-Confidence_Intervals_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;

(1,000 sample proportions)
]

.pull-right[
![](08-Confidence_Intervals_files/figure-html/unnamed-chunk-31-1.png)&lt;!-- --&gt;

(1,000 bootstrap sample proportions)
]




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false,
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
